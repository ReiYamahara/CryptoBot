import torch
import torch.nn as nn
import torch.nn.functional as F
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import ast  # Safely evaluate the config string

# --- CONFIGURATION ---
ALPHA = 1.5           # The "Sensitivity" (Standard Deviations from mean)
WINDOW = 30           # Rolling window size (e.g., 30 periods)
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu")

# ---------------------------------------------------------
# 1. REBUILD THE MODEL (Using Best Config)
# ---------------------------------------------------------
class MarketVAE(nn.Module):
    def __init__(self, input_dim, hidden_1, hidden_2, latent_dim):
        super(MarketVAE, self).__init__()
        self.enc1 = nn.Linear(input_dim, hidden_1)
        self.enc2 = nn.Linear(hidden_1, hidden_2)
        self.z_mean = nn.Linear(hidden_2, latent_dim)
        self.z_log_var = nn.Linear(hidden_2, latent_dim)
        self.dec1 = nn.Linear(latent_dim, hidden_2)
        self.dec2 = nn.Linear(hidden_2, hidden_1)
        self.dec_output = nn.Linear(hidden_1, input_dim)

    def reparameterize(self, mu, log_var):
        if self.training:
            std = torch.exp(0.5 * log_var)
            eps = torch.randn_like(std)
            return mu + eps * std
        else:
            return mu

    def forward(self, x):
        h = torch.tanh(self.enc1(x))
        h = torch.tanh(self.enc2(h))
        mu = self.z_mean(h)
        log_var = self.z_log_var(h)
        z = self.reparameterize(mu, log_var)
        h_dec = torch.tanh(self.dec1(z))
        h_dec = torch.tanh(self.dec2(h_dec))
        reconstruction = self.dec_output(h_dec)
        return reconstruction, mu, log_var

def load_best_model(input_dim):
    # 1. Read Config
    with open("MLP_VAE_Strategy/best_config.txt", "r") as f:
        config_str = f.read()
        config = ast.literal_eval(config_str)
    
    print(f"Loading Best Configuration: {config}")

    # 2. Initialize Model
    model = MarketVAE(
        input_dim=input_dim,
        hidden_1=config['hidden_1'],
        hidden_2=config['hidden_2'],
        latent_dim=config['latent_dim']
    ).to(DEVICE)

    # 3. Load Weights
    model.load_state_dict(torch.load("MLP_VAE_Strategy/vae_model_mlp.pth", map_location=DEVICE))
    model.eval() # Set to evaluation mode
    return model

# ---------------------------------------------------------
# 2. CALCULATE SIGNALS
# ---------------------------------------------------------
def process_dataset(name, filepath, model):
    print(f"\nProcessing {name}...")
    
    # Load Data
    df = pd.read_csv(filepath)
    
    # Prepare Features for Model (Drop Metadata)
    cols_to_drop = ['timestamp', 'symbol', 'label', 'open', 'high', 'low', 'close', 'volume', 'trades', 'Unnamed: 0']
    feature_cols = [c for c in df.columns if c not in cols_to_drop]
    
    features = torch.tensor(df[feature_cols].values, dtype=torch.float32).to(DEVICE)
    
    # 1. Get Reconstruction Error (Row by Row)
    with torch.no_grad():
        recon, _, _ = model(features)
        # MSE per row (keepdim=False results in a vector of errors)
        # We average across the 36 features to get 1 single error number per row
        loss_per_row = F.mse_loss(recon, features, reduction='none').mean(dim=1)
        
    # Convert to Numpy for Pandas
    errors = loss_per_row.cpu().numpy()
    df['recon_error'] = errors
    
    # 2. Calculate Dynamic Thresholds (Rolling Stats)
    # We use a rolling window to adapt to changing market volatility
    rolling_mean = df['recon_error'].rolling(window=WINDOW).mean()
    rolling_std = df['recon_error'].rolling(window=WINDOW).std()
    
    # Handle NaN from rolling window (fill with first valid value)
    rolling_mean.fillna(method='bfill', inplace=True)
    rolling_std.fillna(method='bfill', inplace=True)
    
    # Define Bands
    upper_band = rolling_mean + (ALPHA * rolling_std)
    lower_band = rolling_mean - (ALPHA * rolling_std)
    
    df['upper_band'] = upper_band
    df['lower_band'] = lower_band
    
    # 3. Generate Signals
    # Logic:
    # 1 (Buy/Long)  = Error is LOW (Stable, Predictable Market)
    # -1 (Sell/Short) = Error is HIGH (Volatile, Anomaly)
    # 0 (Hold)      = Error is Normal (Between bands)
    
    conditions = [
        (df['recon_error'] > upper_band), # High Error -> Sell/Exit
        (df['recon_error'] < lower_band)  # Low Error -> Buy/Entry
    ]
    choices = [-1, 1] # -1 = Sell, 1 = Buy
    
    # Default is 0 (Hold)
    df['vae_signal'] = np.select(conditions, choices, default=0)
    
    # Print Stats
    counts = df['vae_signal'].value_counts()
    print(f"Signal Distribution for {name}:")
    print(counts)
    
    return df

# ---------------------------------------------------------
# 3. MAIN EXECUTION
# ---------------------------------------------------------
def main():
    # Load one file just to get input_dim
    temp_df = pd.read_csv("MLP_VAE_Strategy/train_data.csv")
    cols_to_drop = ['timestamp', 'symbol', 'label', 'open', 'high', 'low', 'close', 'volume', 'trades', 'Unnamed: 0']
    input_dim = len([c for c in temp_df.columns if c not in cols_to_drop])
    
    # Load Model
    model = load_best_model(input_dim)
    
    # Process All Splits
    train_df = process_dataset("Train", "MLP_VAE_Strategy/train_data.csv", model)
    val_df = process_dataset("Validation", "MLP_VAE_Strategy/val_data.csv", model)
    test_main_df = process_dataset("Test (Main)", "MLP_VAE_Strategy/test_main.csv", model)
    test_holdout_df = process_dataset("Test (Holdout)", "MLP_VAE_Strategy/test_holdout.csv", model)
    
    # Save New CSVs with Signals
    train_df.to_csv("MLP_VAE_Strategy/train_signals.csv", index=False)
    val_df.to_csv("MLP_VAE_Strategy/val_signals.csv", index=False)
    test_main_df.to_csv("MLP_VAE_Strategy/test_main_signals.csv", index=False)
    test_holdout_df.to_csv("MLP_VAE_Strategy/test_holdout_signals.csv", index=False)
    
    print("\nProcessing Complete. Signal files saved.")
    
    # Optional: Plot the last 500 points of Test Main to visualize
    plt.figure(figsize=(12, 6))
    subset = test_main_df.iloc[-500:]
    plt.plot(subset['recon_error'], label='Reconstruction Error', color='blue', alpha=0.6)
    plt.plot(subset['upper_band'], label='Upper Band (Sell)', color='red', linestyle='--')
    plt.plot(subset['lower_band'], label='Lower Band (Buy)', color='green', linestyle='--')
    plt.title(f"VAE Anomaly Detection (Alpha={ALPHA})")
    plt.legend()
    plt.savefig("MLP_VAE_Strategy/signals_visualization.png")
    print("Visualization saved to signals_visualization.png")

if __name__ == "__main__":
    main()